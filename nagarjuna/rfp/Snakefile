configfile: "config.json"

samples = config['samples'].keys()
#samples = ['test']
bowtie1_index = '/data/rajewsky/indices/dm6_bowtie_1.1.1/dm6.fa'
missmatches = 0
# min and max readlength for mapped reads filtering
min_read_length = 27
max_read_length = 33
illumina_adaptors = '../../shared/illumina_adaptors.fa'
dm6_gtf = '/data/rajewsky/annotation/dm6/latest/ensGene.proper.gtf'
dm6_tophat_tx_index = '/data/rajewsky/annotation/dm6/tophat_tx_index/ensGene.proper'

root_data_dir = 'data/'

read_suffix = '{sample}.fastq.gz'

raw_reads_path = root_data_dir + 'reads/raw/'
raw_reads = raw_reads_path + read_suffix

trimmed_reads_path = root_data_dir + 'reads/trimmed/'
trimmed_reads = trimmed_reads_path + read_suffix

# pattern of clean fastq.gz, trimmed and without umis
clean_reads_path = root_data_dir + 'reads/clean/'
clean_reads = clean_reads_path + read_suffix
# extract 4 umis from both side
umi_extraction_regex = "'(?P<umi_1>.{4}).*(?P<umi_2>.{4})'"

# mapping steps:
# first we map to rRNA
dm6_rRNA_bowtie_index = '/data/rajewsky/indices/dm6_rRNA_bowtie_1.2.2/dm6_rRNA'

mapping_root = root_data_dir + 'mapping/'

# ribodepletion logs
ribo_depletion_path = mapping_root + 'ribo_depletion/'
ribo_depletion_log = ribo_depletion_path + '{sample}.log'
ribo_depletion_pipe = ribo_depletion_path + '{sample}.pipe.fasta'
ribo_depletion_mapped = ribo_depletion_path + '{sample}.mapped.sam'

# tophat output
tophat_out_path = mapping_root + 'tophat/'
tophat_out = tophat_out_path + "{sample}"
tophat_out_mapped = tophat_out + '/accepted_hits.bam'
tophat_out_indexed = tophat_out_mapped + '.bai'

deduped_out_path = mapping_root + 'deduped/'
deduped_out = deduped_out_path + '{sample}.bam'
deduped_log = deduped_out_path + '{sample}.log'
deduped_filtered_out = deduped_out_path + '{sample}_filtered.bam'

read_dist_suffix = '_read_length_dist.txt'
read_dist_out = deduped_out_path + '{sample}' + read_dist_suffix

# feature counts out
fc_out_path = root_data_dir + 'counts/'
fc_out = fc_out_path + 'feature_counts.rds'
fc_in = expand(deduped_filtered_out, sample = samples)

bigwig_out_path = root_data_dir + 'bigwig/'
bigwig_out = bigwig_out_path + '{sample}.{strand}.bw'

rule all:
	input:
		expand(read_dist_out, sample=samples),
		expand(bigwig_out, sample=samples, strand=['forward', 'reverse']),
		fc_out

# download from ena instead of SRA
rule download_sra:
	output:
		raw_reads
	params: 
		sample_sra= lambda wildcards: config['samples'][wildcards.sample],
		sample_prefix= config['ena_prefix']
	shell:
		"""
		wget -x -O {output} {params.sample_prefix}{params.sample_sra}.fastq.gz
		"""

rule index_bam_file:
	input:
		'{file}.bam'
	output:
		temp('{file}.bam.bai')
	shell:
		"samtools index {input}"

rule get_read_length_dist:
	input:
		'{file}.bam'
	output:
		'{file}' + read_dist_suffix
	shell:
		 'samtools view {input} | awk \'{{print(length($10))}}\' | sort | uniq -c > {output}'

rule trim_with_flexbar:
	input:
		raw_reads
	output:
		pipe(trimmed_reads)
	threads: 4
	shell:
		"""
		mkdir -p {trimmed_reads_path}
		flexbar -qf i1.8 -qt 25 -m 20 --min-read-length 28 --adapter-trim-end RIGHT --adapter-preset SmallRNA \
			-n {threads} -r {input} -t {trimmed_reads_path}{wildcards.sample} -z GZ
		"""

rule get_umis:
	input:
		trimmed_reads
	output:
		clean_reads
	params:
		log_file= lambda wildcards: clean_reads_path + wildcards.sample + ".umi_tools.log" 
	shell:
		"umi_tools extract --stdin={input} --bc-pattern={umi_extraction_regex} --extract-method=regex --log={params.log_file} --stdout={output}"
		
rule deplete_r_rna:
	input:
		clean_reads
	output:
		pipe_out= temp(ribo_depletion_pipe),
		mapped= temp(ribo_depletion_mapped),
		logfile= ribo_depletion_log
	threads: 4
	shell:
		"bowtie -p {threads} --un {output.pipe_out} -v 0 {dm6_rRNA_bowtie_index} {input} > {output.mapped} 2> {output.logfile}" 

rule map_with_tophat:
	input:
		ribo_depletion_pipe
	output:
		temp(tophat_out_mapped)
	params:
		out_dir= lambda wildcards: expand(tophat_out, sample = wildcards.sample)
	threads: 4
	shell:
		"""
		tophat 	--no-coverage-search --bowtie1 --max-intron-length 260000 --num-threads {threads} --max-multihits 1 \
			--GTF {dm6_gtf} --no-novel-juncs --transcriptome-index {dm6_tophat_tx_index} --read-mismatches 0 \
			--library-type fr-firststrand --output-dir {params.out_dir} {bowtie1_index} {input}
		"""

ruleorder:  filter_reads_length > remove_pcr_duplicates

rule remove_pcr_duplicates:
	input:
		mapped= tophat_out_mapped,
		index= tophat_out_indexed
	output:
		out= deduped_out,
		logfile= deduped_log
	shell:
		"umi_tools dedup --stdin={input.mapped} --log={output.logfile} > {output.out}"

rule filter_reads_length:
	input:
		deduped_out
	output:
		temp(deduped_filtered_out)
	shell:
		'samtools view -h {input} | awk \'length($10)>={min_read_length} && length($10)<={max_read_length} || $1 ~ /^@/ \' | samtools view -hub > {output}'

rule count_features:
	input:
		fc_in
	output:
		fc_out		
	params:
		annotation= dm6_gtf
	threads: 16
	script:
		'code/R/featureCounts.R'

rule create_normalised_bigwig:
	input:
		mapped_reads=deduped_filtered_out,
		index=deduped_filtered_out + '.bai'
	output:
		'data/bigwig/{sample}.{strand}.bw'
	shell:
		"""
		bamCoverage --bam {input.mapped_reads} -o {output} \
			--normalizeUsing RPKM \
			--binSize 1 \
			--filterRNAstrand {wildcards.strand} 
		"""
